{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7900b6b-06f5-468e-a228-28e6144fed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "API_KEY = 'sk-bedceae2ceba437f944db22706354095'\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f6a0f4-ff13-4088-bbe1-a2007d3ceb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_dividend_detection():\n",
    "    return \"\"\"\n",
    "You are a financial expert.\n",
    "\n",
    "Go through this content and check if there is any mention of dividend per share\n",
    "\n",
    "Your task is to find the dividend the company pays per share.\n",
    "\n",
    "Your output must be in JSON format with the following keys:\n",
    "\n",
    "{\n",
    "  \"is_dividend_mentioned\": true/false,\n",
    "  \"dividend_amount\": \"...\"\n",
    "}\n",
    "\n",
    "Avoid making assumptions beyond the text.\n",
    "\"\"\"\n",
    "\n",
    "def make_prompt_dividend_calculation():\n",
    "    return \"\"\"\n",
    "You are a financial expert.\n",
    "\n",
    "Go through this content and assimilate all the information about dividends\n",
    "\n",
    "Your task is to find the dividend the company pays in all forms.\n",
    "\n",
    "Your output must be in JSON format with the following keys:\n",
    "\n",
    "{\n",
    "  \"dividend_amount_paid\": \"...\"\n",
    "}\n",
    "\n",
    "Avoid making assumptions beyond the text. Dont put anything extra, just one absolute value, dividend per share. \n",
    "So it should not be a large value\n",
    "Do not put any text like per share or currency name or %. if you cannot find anything put 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4ed31d-1acf-45c9-9f11-e2c8466d12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dividend_context(res_dic):\n",
    "    context_string=''\n",
    "    for res_dic in results:\n",
    "        if res_dic['is_dividend_mentioned']==True:\n",
    "            #print(res_dic)            \n",
    "            context_string+=res_dic['page_text']+'\\n'\n",
    "    return context_string\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5946b47-0eb8-48bc-87c5-2a6b70c80f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b18f7b-76a1-443d-83da-f868e62e79a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a00ab0-b111-4218-bcf1-8025d81891c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_codes=['QNBK','QFBQ','QNCD','QNNS','SIIS','ZHCD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9082aaea-94ae-44ae-a03b-4c78ffc23478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping QNBK, 2015 - already in CSV\n",
      "Skipping QNBK, 2014 - already in CSV\n",
      "Skipping QNBK, 2016 - already in CSV\n",
      "Skipping QNBK, 2017 - already in CSV\n",
      "Skipping QNBK, 2013 - already in CSV\n",
      "Skipping QNBK, 2012 - already in CSV\n",
      "Skipping QNBK, 2010 - already in CSV\n",
      "Skipping QNBK, 2011 - already in CSV\n",
      "Skipping QNBK, 2008 - already in CSV\n",
      "2020.pdf 2020\n",
      "84\n",
      "will analyze page 4\n",
      "**********\n",
      "will analyze page 12\n",
      "**********\n",
      "will analyze page 54\n",
      "**********\n",
      "will analyze page 55\n",
      "**********\n",
      "will analyze page 59\n",
      "**********\n",
      "will analyze page 60\n",
      "**********\n",
      "will analyze page 61\n",
      "**********\n",
      "will analyze page 69\n",
      "**********\n",
      "will analyze page 73\n",
      "**********\n",
      "will analyze page 76\n",
      "**********\n",
      "will analyze page 77\n",
      "**********\n",
      "will analyze page 78\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0.45\"\n",
      "}\n",
      "0.45\n",
      "Saved 2020: 0.45\n",
      "2021.pdf 2021\n",
      "85\n",
      "will analyze page 4\n",
      "**********\n",
      "will analyze page 54\n",
      "**********\n",
      "will analyze page 55\n",
      "**********\n",
      "will analyze page 59\n",
      "**********\n",
      "will analyze page 61\n",
      "**********\n",
      "will analyze page 70\n",
      "**********\n",
      "will analyze page 74\n",
      "**********\n",
      "will analyze page 77\n",
      "**********\n",
      "will analyze page 78\n",
      "**********\n",
      "will analyze page 79\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0.55\"\n",
      "}\n",
      "0.55\n",
      "Saved 2021: 0.55\n",
      "Skipping QNBK, 2009 - already in CSV\n",
      "2023.pdf 2023\n",
      "226\n",
      "will analyze page 9\n",
      "**********\n",
      "will analyze page 121\n",
      "**********\n",
      "will analyze page 122\n",
      "**********\n",
      "will analyze page 123\n",
      "**********\n",
      "will analyze page 131\n",
      "**********\n",
      "will analyze page 135\n",
      "**********\n",
      "will analyze page 136\n",
      "**********\n",
      "will analyze page 137\n",
      "**********\n",
      "will analyze page 153\n",
      "**********\n",
      "will analyze page 161\n",
      "**********\n",
      "will analyze page 168\n",
      "**********\n",
      "will analyze page 169\n",
      "**********\n",
      "will analyze page 171\n",
      "**********\n",
      "will analyze page 182\n",
      "**********\n",
      "will analyze page 190\n",
      "**********\n",
      "will analyze page 195\n",
      "**********\n",
      "will analyze page 196\n",
      "**********\n",
      "will analyze page 212\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0.65\"\n",
      "}\n",
      "0.65\n",
      "Saved 2023: 0.65\n",
      "2022.pdf 2022\n",
      "180\n",
      "will analyze page 9\n",
      "**********\n",
      "will analyze page 115\n",
      "**********\n",
      "will analyze page 116\n",
      "**********\n",
      "will analyze page 117\n",
      "**********\n",
      "will analyze page 125\n",
      "**********\n",
      "will analyze page 129\n",
      "**********\n",
      "will analyze page 130\n",
      "**********\n",
      "will analyze page 147\n",
      "**********\n",
      "will analyze page 155\n",
      "**********\n",
      "will analyze page 162\n",
      "**********\n",
      "will analyze page 163\n",
      "**********\n",
      "will analyze page 165\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0.60\"\n",
      "}\n",
      "0.6\n",
      "Saved 2022: 0.6\n",
      "2019.pdf 2019\n",
      "84\n",
      "will analyze page 4\n",
      "**********\n",
      "will analyze page 12\n",
      "**********\n",
      "will analyze page 54\n",
      "**********\n",
      "will analyze page 55\n",
      "**********\n",
      "will analyze page 59\n",
      "**********\n",
      "will analyze page 60\n",
      "**********\n",
      "will analyze page 61\n",
      "**********\n",
      "will analyze page 69\n",
      "**********\n",
      "will analyze page 73\n",
      "**********\n",
      "will analyze page 76\n",
      "**********\n",
      "will analyze page 77\n",
      "**********\n",
      "will analyze page 78\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0.60\"\n",
      "}\n",
      "0.6\n",
      "Saved 2019: 0.6\n",
      "Skipping QNBK, 2018 - already in CSV\n",
      "2024.pdf 2024\n",
      "254\n",
      "will analyze page 10\n",
      "**********\n",
      "will analyze page 54\n",
      "**********\n",
      "will analyze page 131\n",
      "**********\n",
      "will analyze page 132\n",
      "**********\n",
      "will analyze page 133\n",
      "**********\n",
      "will analyze page 141\n",
      "**********\n",
      "will analyze page 145\n",
      "**********\n",
      "will analyze page 146\n",
      "**********\n",
      "will analyze page 147\n",
      "**********\n",
      "will analyze page 165\n",
      "**********\n",
      "will analyze page 174\n",
      "**********\n",
      "will analyze page 175\n",
      "**********\n",
      "will analyze page 183\n",
      "**********\n",
      "will analyze page 185\n",
      "**********\n",
      "will analyze page 188\n",
      "**********\n",
      "will analyze page 198\n",
      "**********\n",
      "will analyze page 206\n",
      "**********\n",
      "will analyze page 211\n",
      "**********\n",
      "will analyze page 212\n",
      "**********\n",
      "will analyze page 229\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0.37\"\n",
      "}\n",
      "0.37\n",
      "Saved 2024: 0.37\n",
      "2015.pdf 2015\n",
      "74\n",
      "will analyze page 32\n",
      "**********\n",
      "will analyze page 33\n",
      "**********\n",
      "will analyze page 34\n",
      "**********\n",
      "will analyze page 44\n",
      "**********\n",
      "will analyze page 53\n",
      "**********\n",
      "will analyze page 65\n",
      "**********\n",
      "will analyze page 70\n",
      "**********\n",
      "will analyze page 71\n",
      "**********\n",
      "will analyze page 72\n",
      "**********\n",
      "will analyze page 73\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"160000\"\n",
      "}\n",
      "160000.0\n",
      "Saved 2015: 160000.0\n",
      "2014.pdf 2014\n",
      "50\n",
      "will analyze page 17\n",
      "**********\n",
      "will analyze page 18\n",
      "**********\n",
      "will analyze page 19\n",
      "**********\n",
      "will analyze page 27\n",
      "**********\n",
      "will analyze page 35\n",
      "**********\n",
      "will analyze page 45\n",
      "**********\n",
      "will analyze page 46\n",
      "**********\n",
      "will analyze page 47\n",
      "**********\n",
      "will analyze page 48\n",
      "**********\n",
      "will analyze page 49\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"38.9\"\n",
      "}\n",
      "38.9\n",
      "Saved 2014: 38.9\n",
      "2016.pdf 2016\n",
      "75\n",
      "will analyze page 13\n",
      "**********\n",
      "will analyze page 15\n",
      "**********\n",
      "will analyze page 30\n",
      "**********\n",
      "will analyze page 31\n",
      "**********\n",
      "will analyze page 32\n",
      "**********\n",
      "will analyze page 42\n",
      "**********\n",
      "will analyze page 51\n",
      "**********\n",
      "will analyze page 63\n",
      "**********\n",
      "will analyze page 69\n",
      "**********\n",
      "will analyze page 70\n",
      "**********\n",
      "will analyze page 71\n",
      "**********\n",
      "will analyze page 72\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0\"\n",
      "}\n",
      "0.0\n",
      "Saved 2016: 0.0\n",
      "2017.pdf 2017\n",
      "36\n",
      "will analyze page 6\n",
      "**********\n",
      "will analyze page 12\n",
      "**********\n",
      "will analyze page 18\n",
      "**********\n",
      "will analyze page 19\n",
      "**********\n",
      "will analyze page 24\n",
      "**********\n",
      "will analyze page 26\n",
      "**********\n",
      "will analyze page 30\n",
      "**********\n",
      "will analyze page 33\n",
      "**********\n",
      "will analyze page 34\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"25.5\"\n",
      "}\n",
      "25.5\n",
      "Saved 2017: 25.5\n",
      "2013.pdf 2013\n",
      "56\n",
      "will analyze page 21\n",
      "**********\n",
      "will analyze page 22\n",
      "**********\n",
      "will analyze page 23\n",
      "**********\n",
      "will analyze page 32\n",
      "**********\n",
      "will analyze page 40\n",
      "**********\n",
      "will analyze page 50\n",
      "**********\n",
      "will analyze page 52\n",
      "**********\n",
      "will analyze page 53\n",
      "**********\n",
      "will analyze page 54\n",
      "**********\n",
      "will analyze page 55\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"30.2\"\n",
      "}\n",
      "30.2\n",
      "Saved 2013: 30.2\n",
      "2012.pdf 2012\n",
      "80\n",
      "will analyze page 13\n",
      "**********\n",
      "will analyze page 37\n",
      "**********\n",
      "will analyze page 38\n",
      "**********\n",
      "will analyze page 39\n",
      "**********\n",
      "will analyze page 51\n",
      "**********\n",
      "will analyze page 59\n",
      "**********\n",
      "will analyze page 73\n",
      "**********\n",
      "will analyze page 76\n",
      "**********\n",
      "will analyze page 77\n",
      "**********\n",
      "will analyze page 78\n",
      "**********\n",
      "will analyze page 79\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"25.89\"\n",
      "}\n",
      "25.89\n",
      "Saved 2012: 25.89\n",
      "Skipping QFBQ, 2010 - already in CSV\n",
      "2011.pdf 2011\n",
      "31\n",
      "will analyze page 8\n",
      "**********\n",
      "will analyze page 24\n",
      "**********\n",
      "will analyze page 25\n",
      "**********\n",
      "will analyze page 29\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"21,574\"\n",
      "}\n",
      "21574.0\n",
      "Saved 2011: 21574.0\n",
      "2020.pdf 2020\n",
      "85\n",
      "will analyze page 45\n",
      "**********\n",
      "will analyze page 72\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"0\"\n",
      "}\n",
      "0.0\n",
      "Saved 2020: 0.0\n",
      "2021.pdf 2021\n",
      "65\n",
      "will analyze page 9\n",
      "**********\n",
      "will analyze page 17\n",
      "**********\n",
      "will analyze page 25\n",
      "**********\n",
      "will analyze page 26\n",
      "**********\n",
      "will analyze page 29\n",
      "**********\n",
      "will analyze page 35\n",
      "**********\n",
      "will analyze page 43\n",
      "**********\n",
      "will analyze page 49\n",
      "**********\n",
      "will analyze page 52\n",
      "**********\n",
      "will analyze page 53\n",
      "**********\n",
      "will analyze page 60\n",
      "**********\n",
      "will analyze page 62\n",
      "**********\n",
      "will analyze page 63\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": \"12.624\"\n",
      "}\n",
      "12.624\n",
      "Saved 2021: 12.624\n",
      "2023.pdf 2023\n",
      "62\n",
      "will analyze page 19\n",
      "**********\n",
      "will analyze page 20\n",
      "**********\n",
      "will analyze page 23\n",
      "**********\n",
      "will analyze page 30\n",
      "**********\n",
      "will analyze page 37\n",
      "**********\n",
      "will analyze page 43\n",
      "**********\n",
      "will analyze page 47\n",
      "**********\n",
      "will analyze page 49\n",
      "**********\n",
      "will analyze page 56\n",
      "**********\n",
      "will analyze page 59\n",
      "**********\n",
      "will analyze page 60\n",
      "**********\n",
      "{\n",
      "  \"dividend_amount_paid\": 0\n",
      "}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'int' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m dic_res \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)    \n\u001b[1;32m     80\u001b[0m dividend_amount_paid\u001b[38;5;241m=\u001b[39mdic_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdividend_amount_paid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdividend_amount_paid\u001b[49m:\n\u001b[1;32m     82\u001b[0m     dividend_amount_paid\u001b[38;5;241m=\u001b[39mdividend_amount_paid\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "api_client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "output_csv = Path(\"dividend_history_per_share.csv\")\n",
    "\n",
    "# Load existing data with proper nested structure\n",
    "existing_data = {}\n",
    "if output_csv.exists():\n",
    "    with open(output_csv, mode='r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            company = row['company_code']\n",
    "            year = int(row['year'])\n",
    "            amount = float(row['dividend_amount_paid'])\n",
    "            \n",
    "            if company not in existing_data:\n",
    "                existing_data[company] = {}\n",
    "            existing_data[company][year] = amount\n",
    "\n",
    "\n",
    "for company_code in company_codes:\n",
    "\n",
    "\n",
    "    \n",
    "    # read through all annual reports in the folder\n",
    "    report_files_location=f'../extra/{company_code}_annual_reports/'\n",
    "    for file_name in os.listdir(report_files_location):\n",
    "        if '.DS' in file_name:\n",
    "            continue    \n",
    "        year = int(file_name.split('.pdf')[0])\n",
    "        \n",
    "        if company_code in existing_data and year in existing_data[company_code]:\n",
    "            print(f'Skipping {company_code}, {year} - already in CSV')\n",
    "            continue\n",
    "                \n",
    "        print(file_name,year)\n",
    "    \n",
    "        try:\n",
    "            reader = PdfReader(f\"../extra/{company_code}_annual_reports/{file_name}\")\n",
    "        except:\n",
    "            print('issues reading')\n",
    "            continue\n",
    "        print(len(reader.pages))\n",
    "        system_prompt=make_prompt_dividend_detection()\n",
    "        results=[]\n",
    "        for page_num in range(len(reader.pages)):        \n",
    "            page = reader.pages[page_num]\n",
    "            #print(page.extract_text())\n",
    "            text=page.extract_text()\n",
    "            if len(text)<50:\n",
    "                continue\n",
    "            if 'dividen' not in text.lower():\n",
    "                continue\n",
    "            print(f'will analyze page {page_num}')\n",
    "            response = api_client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                response_format={'type': 'json_object'}\n",
    "            )    \n",
    "            #print(response.choices[0].message.content)\n",
    "            dic_res = json.loads(response.choices[0].message.content)\n",
    "            dic_res['page_num']=page_num\n",
    "            dic_res['page_text']=text\n",
    "            results.append(dic_res)\n",
    "            print('*'*10)\n",
    "    \n",
    "        context_string=make_dividend_context(dic_res)\n",
    "        system_prompt = make_prompt_dividend_calculation()\n",
    "        response = api_client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": context_string}\n",
    "            ],\n",
    "            response_format={'type': 'json_object'}\n",
    "        )    \n",
    "        print(response.choices[0].message.content)\n",
    "        dic_res = json.loads(response.choices[0].message.content)    \n",
    "        dividend_amount_paid=dic_res['dividend_amount_paid']\n",
    "        if ',' in dividend_amount_paid:\n",
    "            dividend_amount_paid=dividend_amount_paid.replace(',','')\n",
    "        try:\n",
    "            print(float(dividend_amount_paid))         \n",
    "            dividend_amount_paid=float(dividend_amount_paid)\n",
    "        except:\n",
    "            print(f'something fishy in {dividend_amount_paid}')\n",
    "            continue\n",
    "\n",
    "        # Append to CSV after each successful year\n",
    "        with open(output_csv, mode='a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=['company_code', 'year', 'dividend_amount_paid'])\n",
    "            if f.tell() == 0:  # Write header if file is empty\n",
    "                writer.writeheader()\n",
    "            writer.writerow({\n",
    "                'company_code': company_code,\n",
    "                'year': year,\n",
    "                'dividend_amount_paid': dividend_amount_paid\n",
    "            })\n",
    "            \n",
    "        print(f\"Saved {year}: {dividend_amount_paid}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194a9f8-9fde-4677-a0fe-54d16ab0b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be7326-7331-4531-8994-2211620180b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "# api_client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "# years=[i for i in range(2015,2025)]\n",
    "\n",
    "# for year in years:\n",
    "#     # Skip if already processed\n",
    "#     if year in existing_data:\n",
    "#         print(f\"Skipping {year} - already in CSV\")\n",
    "#         continue    \n",
    "#     print(year)\n",
    "#     file_name=f'04-annual-financial-english-{year}.pdf'\n",
    "#     try:\n",
    "#         reader = PdfReader(f\"ZHCD.QA/{file_name}\")\n",
    "#     except:\n",
    "#         print('issues reading')\n",
    "#         continue\n",
    "#     print(len(reader.pages))\n",
    "\n",
    "    \n",
    "#     system_prompt=make_prompt_dividend_detection()\n",
    "    \n",
    "#     results=[]\n",
    "#     for page_num in range(len(reader.pages)):\n",
    "#         print(page_num)\n",
    "#         page = reader.pages[page_num]\n",
    "#         #print(page.extract_text())\n",
    "#         text=page.extract_text()\n",
    "#         if len(text)<50:\n",
    "#             continue\n",
    "#         if 'divi' not in text.lower():\n",
    "#             continue\n",
    "        \n",
    "#         response = api_client.chat.completions.create(\n",
    "#             model=\"deepseek-chat\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": system_prompt},\n",
    "#                 {\"role\": \"user\", \"content\": text}\n",
    "#             ],\n",
    "#             response_format={'type': 'json_object'}\n",
    "#         )    \n",
    "#         #print(response.choices[0].message.content)\n",
    "#         dic_res = json.loads(response.choices[0].message.content)\n",
    "#         dic_res['page_num']=page_num\n",
    "#         dic_res['page_text']=text\n",
    "#         results.append(dic_res)\n",
    "#         print('*'*10)\n",
    "\n",
    "#     context_string=make_dividend_context(dic_res)\n",
    "#     system_prompt = make_prompt_dividend_calculation()\n",
    "#     response = api_client.chat.completions.create(\n",
    "#         model=\"deepseek-chat\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": system_prompt},\n",
    "#             {\"role\": \"user\", \"content\": context_string}\n",
    "#         ],\n",
    "#         response_format={'type': 'json_object'}\n",
    "#     )    \n",
    "#     print(response.choices[0].message.content)\n",
    "#     dic_res = json.loads(response.choices[0].message.content)    \n",
    "#     dividend_amount_paid=dic_res['dividend_amount_paid']\n",
    "#     if ',' in dividend_amount_paid:\n",
    "#         dividend_amount_paid=dividend_amount_paid.replace(',','')\n",
    "#     print(float(dividend_amount_paid))      \n",
    "#     # Append to CSV after each successful year\n",
    "#     with open(output_csv, mode='a', newline='') as f:\n",
    "#         writer = csv.DictWriter(f, fieldnames=['year', 'dividend_amount_paid'])\n",
    "#         if f.tell() == 0:  # Write header if file is empty\n",
    "#             writer.writeheader()\n",
    "#         writer.writerow({\n",
    "#             'year': year,\n",
    "#             'dividend_amount_paid': dividend_amount_paid\n",
    "#         })\n",
    "        \n",
    "#     print(f\"Saved {year}: {dividend_amount_paid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6a1a0-4f36-4412-908c-59ab3b645223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f20bc-ce38-4676-a920-5b51838ee689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# context_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f570ed-3187-4b58-a32f-1357f6c07cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd34e7b-e2ad-483a-b91e-e9d0e0dd18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dic_res['dividend_amount_paid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccd30f-7035-4d23-9456-aea1e11f38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = reader.pages[9]\n",
    "        \n",
    "text=page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bf86f-3dea-4de1-8c1d-1833671f89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab1aa8-697f-4f4f-ab10-3cb8db16d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece8f95-fed0-4440-93eb-58bc8a4decf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_string=make_dividend_context(dic_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0fc30-a526-4ec3-a037-ff323e6435d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cd996-51ff-4c50-848a-da086461c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = make_prompt_dividend_calculation()\n",
    "response = api_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": context_string}\n",
    "    ],\n",
    "    response_format={'type': 'json_object'}\n",
    ")    \n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403dabb6-b33d-4caf-a169-cfc6357b52af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310k",
   "language": "python",
   "name": "py310k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
